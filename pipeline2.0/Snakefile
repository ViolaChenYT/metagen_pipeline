import os
from snakemake.io import glob_wildcards
method_list = ("target_species","abundant_species", "database","assembly")
filter_list = ("filt","unfilt")

wildcard_constraints:
   species = '\w+',
   filt = '\w+'

rule all:
  input:
    expand("output/{sample}/performance.csv",species=method_list,sample=config)

##########################################################################################
## Alignment methods / database preparation
rule assembly:
    input:
        r1 = lambda wc: config[wc.sample]['r1'],
        r2 = lambda wc: config[wc.sample]['r2']
    output:
        fa = "output/{sample}/assembly/final.contigs.fa"
    benchmark:
        "benchmarks/{sample}/megahit_resource_usage.txt"
    threads:
        16
    shell:
        "megahit -1 {input.r1} -2 {input.r2} -f -o output/{wildcards.sample}/assembly -t {threads}"

rule mummmer_assembly_to_ref:
    input:
        ref = lambda wc: config[wc.sample]['ref'],
        assembly = rules.assembly.output.fa
    output:
        "output/{sample}/assembly/mummer.mums"
    shell:
        "mummer {input.ref} {input.assembly} > {output}"

rule get_nonref_contig:
    input:
        assembly = "output/{sample}/assembly/final.contigs.fa",
        mummer =  rules.mummmer_assembly_to_ref.output
    output:
        temp("output/{sample}/assembly/passed_contigs.txt")
    shell:
        "python refs/filter_contigs.py {input.assembly} {input.mummer} > {output}"

rule filter_assembly:
    input:
        nonrefcontig = rules.get_nonref_contig.output,
        assembly =  "output/{sample}/assembly/final.contigs.fa",
        ref = lambda wc: config[wc.sample]['ref'],
        abund = "output/{sample}/abundant_species.fasta"
    output:
        "output/{sample}/assembly.fasta"
    shell:
        "grep -w -A 1 -f {input.nonrefcontig} {input.assembly} > {output} && cat {input.abund} >> {output}"

rule index_db:
    input:
        db = "gtdb/uhgg_reps.fasta.gz"
    output:
        "gtdb/database.mmi"
    shell:
        "minimap2 -x sr -t 10 -d {output} {input.db}"

rule get_abund_species:
    input:
        r1 = lambda wc: config[wc.sample]['r1'],
        db = "gtdb/gtdb_sketch"
    output:
        "output/{sample}/abundant_species.csv"
    params:
        sig = "output/{sample}/{sample}.sig"
    conda:
        "workflow/envs/sim.yaml"
    shell:
        "sourmash sketch dna -p abund {input.r1} -o {params.sig} &&"
        "sourmash gather {params.sig} {input.db} -o {output} --threshold=0.0"

rule get_close_species:
    input:
        ref = lambda wc: config[wc.sample]['ref'],
        db = "gtdb/gtdb_sketch"
    output:
        "output/{sample}/close_species.csv"
    conda:
        "workflow/envs/sim.yaml"
    params:
        sig = "output/{sample}/close_species.sig"
    shell:
        "sourmash sketch dna {input.ref} -o {params.sig} && "
        "sourmash search {params.sig} {input.db} -o {output} --threshold=0.0 --ignore-abundance"

rule build_metagenome_abund:
    input:
        csv = rules.get_abund_species.output,
        ref = lambda wc: config[wc.sample]['ref'],
        close = rules.get_close_species.output
    output:
        "output/{sample}/abundant_species.fasta"
    params:
        species = lambda wc: config[wc.sample]["species"],
        sample = lambda wc: wc.sample
        # t = lambda wc: wc.threshold
    shell:
        "./workflow/scripts/combine_fasta.sh {input.csv} {output} {input.ref} '{params.species}' {input.close}"

rule build_metagenome_close:
    input:
        csv = rules.get_close_species.output,
        ref = lambda wc: config[wc.sample]['ref']
    output:
        "output/{sample}/close_species.fasta"
    params:
        lambda wc: config[wc.sample]["species"]
    shell:
        "./workflow/scripts/combine_fasta_close.sh {input.csv} {output} {input.ref} '{params.species}' "

rule build_target_reference:
    input:
        ref = lambda wc: config[wc.sample]['ref']
    output:
        "output/{sample}/target_species.fasta"
    shell:
        "cat {input.ref} > {output}"

rule build_consensus_reference: # don't think it was ever in use
    input:
        ref = lambda wc: config[wc.sample]['ref'],
        vcf = "output/{sample}/target_species.filt.vcf"
    output:
        "output/{sample}/consensus.fasta"
    shell:
        "python workflow/scripts/consensus_ref.py {input.ref} {input.vcf} {output}"

##########################################################################################
## Getting alignment
rule align_large:
    input:
        r1 = lambda wc: config[wc.sample]['r1'],
        r2 = lambda wc: config[wc.sample]['r2'],
        ref = "gtdb/database.mmi"
    output:
        bam = temp('output/{sample}/database.bam')
    conda:
        'workflow/envs/mapping.yaml' # include minimap2
    benchmark:
        "benchmarks/{sample}/align_large_resource_usage.txt"
    params:
        lambda wc: wc.sample
    threads:
        16
    shell:
        "minimap2 -ax sr -t {threads} --split-prefix=foo {input.ref} {input.r1} {input.r2} | samtools sort -@ {threads} -o {output.bam}"

rule alignment: 
    input:
        r1 = lambda wc: config[wc.sample]['r1'],
        r2 = lambda wc: config[wc.sample]['r2'],
        ref = "output/{sample}/{species}.fasta"
    output:
        bam = 'output/{sample}/{species}.bam'
    conda:
        'workflow/envs/mapping.yaml' # include minimap2
    threads:
        12
    shell:
        "minimap2 -t {threads} -ax sr --secondary=yes {input.ref} {input.r1} {input.r2} | samtools sort -@ {threads} -o {output.bam}"
ruleorder:  align_large > alignment

###############################################################################
## Samtools methods
rule samtools_index: 
    input:
        "output/{sample}/{placeholder}.bam"
    output:
        'output/{sample}/{placeholder}.bam.bai'
    conda:
        'workflow/envs/mapping.yaml'
    shell:
        'samtools index {input}'

rule bamfilter:
    input:
        "output/{sample}/{species}.bam",
        "output/{sample}/{species}.bam.bai"
    output:
        "output/{sample}/{species}.{filt}.bam"
    conda:
        'workflow/envs/mapping.yaml'
    params:
        "{filt}",
        lambda wc: config[wc.sample]['ref']
    script:
        'workflow/scripts/bamfilter.py'

rule sort_bam:
    input: 
        bam = "output/{sample}/{species}.{filt}.bam"
    output:
        "output/{sample}/{species}.{filt}.sorted.bam"
    shell:
        "samtools sort {input.bam} -o {output}"

################################################################################
## Variant calling
rule lofreq:
    input:
        ref = lambda wc: config[wc.sample]['ref'],
        filt_bam = "output/{sample}/{species}.{filt}.sorted.bam",
        idx = "output/{sample}/{species}.{filt}.sorted.bam.bai"
    output:
        "output/{sample}/{species}.{filt}.vcf"
    conda:
        'workflow/envs/mapping.yaml'
    threads:
        8
    shell: 
        "lofreq faidx {input.ref} && lofreq call-parallel --pp-threads {threads} -f {input.ref} -o {output} --verbose {input.filt_bam}"


rule get_lofreq_indel_qual:
    input:
        ref = lambda wc: config[wc.sample]['ref'],
        filt_bam = "output/{sample}/{species}.{filt}.bam",
        idx = "output/{sample}/{species}.{filt}.bam.bai"
    output:
        "output/{sample}/{species}.{filt}.indel.bam"
    conda:
        'workflow/envs/mapping.yaml'
    shell:
        "lofreq faidx {input.ref} && lofreq indelqual --dindel -f {input.ref} -o {output} {input.filt_bam}"


rule lofreq_indel:
    input:
        ref = lambda wc: config[wc.sample]['ref'],
        bam = rules.get_lofreq_indel_qual.output
    output:
        "output/{sample}/{species}.{filt}.indel.vcf"
    conda:
        'workflow/envs/mapping.yaml'
    threads:
        8
    shell: 
        "lofreq call --call-indels -f {input.ref} -o {output} --verbose {input.bam}"


###################################################################################
## Pileup and coverage information (not using at the moment)
rule pileup:
    input:
        ref = "refs/{species}.fasta",
        bam = rules.alignment.output.bam
    output:
        gz = "output/{sample}/{sample}.pileup.gz"
    conda:
        'workflow/envs/mapping.yaml'
    shell:
        "samtools mpileup -E -f {input.ref} {input.bam} | gzip > {output.gz}"

rule coverage_txt:
    input:
        "output/{sample}/{species}.{filt}.bam"
    output:
        "output/{sample}/{species}.{filt}.coverage.txt.gz"
    conda:
        'workflow/envs/mapping.yaml'
    shell:
        "genomeCoverageBed -d -ibam {input} | gzip > {output}"

rule coverage_avg:
    input:
        bam = 'output/{sample}/{species}.bam',
        bai = rules.samtools_index.output
    output:
        "output/{sample}/{species}.{filt}.coverage.summary.txt"
    conda:
        'workflow/envs/mapping.yaml'
    shell:
        "samtools depth -aa {input.bam} | awk '{{sum+=$3}} END {{print sum/NR}}' > {output}"

rule annotate_gene:
    input:
        "output/{sample}/{species}.{filt}.{mapper}.vcf"
    output:
        "output/{sample}/{species}.{filt}.{mapper}.annotated.vcf"
    params:
        snpeff_species = lambda wc: config[wc.sample]['snpeff_species']
    conda:
        'workflow/envs/mapping.yaml'
    shell:
        "sed -i 's/NC_011750.1/Chromosome/g' {input} && "
        "(snpeff {params.snpeff_species} {input} > {output}) && "
        "mv ./snpEff* output/{wildcards.sample}/"

##################################################################################
## Process Results and Generate Figure
rule process_result:
    input:
        expand("output/{sample}/{method}.filt.vcf", method=method_list, sample=config),
        expand("output/{sample}/{method}.filt.sorted.bam", method=method_list,sample=config)
    output:
        "output/{sample}/performance.csv",
        "output/{sample}/read_mapping_perf.jpg",
        "output/{sample}/SNP_perf.jpg",
        "output/{sample}/FP_reads.json"
    conda:
        'workflow/envs/plotting.yaml'
    params:
        samp = "{sample}",
        methods = list(method_list),
        ref = lambda wc: config[wc.sample]['ref'],
        snp_lst = lambda wc: config[wc.sample]['isolate']
    script:
        "workflow/scripts/process_vcf.py"